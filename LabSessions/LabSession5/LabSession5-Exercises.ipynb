{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Streams\n",
    "## Computer Vision and Image Processing - Lab Session 5 - Exercises\n",
    "### Prof: Luigi Di Stefano, luigi.distefano@unibo.it\n",
    "### Tutor: Pierluigi Zama Ramirez, pierluigi.zama@unibo.it - Riccardo Spezialetti, riccardo.spezialetti@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: Distance Functions between images\n",
    "\n",
    "Define three functions to calculate the $L_1$, $L_2$ and $L_{\\infty}$ distances between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def get_img_difference(img1, img2, p):\n",
    "    if img1.shape[-1]==3 and len(img1.shape)==3:\n",
    "        RGB = True\n",
    "    else:\n",
    "        RGB = False\n",
    "\n",
    "    if p==1:\n",
    "        diff = np.abs(img1-img2)\n",
    "        if RGB:\n",
    "            diff = np.sum(diff, axis=-1)\n",
    "\n",
    "    elif p==2:\n",
    "        diff = (img1-img2)**2\n",
    "        if RGB:\n",
    "            diff = np.sum(diff, axis=-1)\n",
    "        diff = np.sqrt(diff)\n",
    "    \n",
    "    elif p==np.inf:\n",
    "        diff = np.abs(img1-img2)\n",
    "        if RGB:\n",
    "            diff = np.max(diff, axis=-1)\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError(\"The value {} is not an accepted distance: accepted distances are {1, 2, np.inf}\".format(p))\n",
    "\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Two Frame Difference\n",
    "\n",
    "Calculate a Two Frame Difference over frames of a video to detect motion changes. Try different distance functions and visualize results. Test it on \"ex/1.avi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADaCAYAAAC2Arl5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADaklEQVR4nO3bwWnDQBRFUU1wB2rAfbkuN+RS1MikAJMgkQgll3PWf/FWl0GgMeecCwD/3sfVAwD4HYIOECHoABGCDhAh6AARgg4QIegAEYIOECHoABG3vYdjjDN3APCNPT/1e6EDRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKADRAg6QISgA0QIOkCEoANECDpAhKDz5vF4LM/n8+oZwEGCzpt1XZf7/X71DOCg29UD+Hter9eybdvVM4CDxpxz7joc4+wtAHxhT6p9cgGIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeIuO09nHOeuQOAH/JCB4gQdIAIQQeIEHSACEEHiBB0gAhBB4gQdIAIQQeI+ASkUxsDOgfDTgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your solution here\n",
    "# Put the code in try-except statements catch the keyboard exception and release the camera device and \n",
    "# continue with the rest of code.\n",
    "\n",
    "def display_mask_and_change_image(mask, img):\n",
    "    img_copy = img.copy()\n",
    "    img_copy[np.logical_not(mask)] = np.asarray([255,255,255])\n",
    "\n",
    "    mask = np.uint8(mask)*255\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img_copy.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def two_frame_difference_mask(img1, img2, distance, threshold):\n",
    "    diff_img = get_img_difference(img1, img2, distance)\n",
    "    mask = diff_img > threshold\n",
    "    return mask\n",
    "\n",
    "\n",
    "def play_mask_and_image_two_frames(video_path, distance, threshold):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    idx = 0\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret and not frame is None:\n",
    "                if idx == 0:\n",
    "                    previous_frame = np.float32(frame)\n",
    "                else:\n",
    "                    current_frame = np.float32(frame)\n",
    "                    mask = two_frame_difference_mask(current_frame, previous_frame, distance, threshold)\n",
    "                    display_mask_and_change_image(mask, frame)\n",
    "                    clear_output(wait=True)\n",
    "                    previous_frame = current_frame\n",
    "                idx += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If we press stop (jupyter GUI) release the video\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "\n",
    "play_mask_and_image_two_frames('LabSession5Images/video.avi', distance=np.inf, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Three Frame Difference\n",
    "\n",
    "Calculate a Three Frame Difference over frames of a video to detect motion changes. Try different distance functions and visualize results. Test it on \"ex/1.avi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "# Write your solution here\n",
    "def three_frame_difference_mask(img1, img2, img3, distance, threshold):\n",
    "    mask_1 = two_frame_difference_mask(img1, img2, distance, threshold)\n",
    "    mask_2 = two_frame_difference_mask(img2, img3, distance, threshold)\n",
    "    return np.logical_and(mask_1,mask_2)\n",
    "\n",
    "def play_mask_and_image_three_frames(video_path, distance, threshold):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    idx = 0\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret and not frame is None:\n",
    "                if idx == 0:\n",
    "                    frame_1 = np.float32(frame)\n",
    "                elif idx == 1:\n",
    "                    frame_2 = np.float32(frame)\n",
    "                else:\n",
    "                    frame_3 = np.float32(frame)\n",
    "                    mask = three_frame_difference_mask(frame_3, frame_2, frame_1, distance, threshold)\n",
    "                    display_mask_and_change_image(mask, frame)\n",
    "                    clear_output(wait=True)\n",
    "                    frame_1 = frame_2\n",
    "                    frame_2 = frame_3\n",
    "                idx += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If we press stop (jupyter GUI) release the video\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "\n",
    "play_mask_and_image_three_frames('LabSession5Images/video.avi', distance=1, threshold=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Background Subtraction\n",
    "\n",
    "Apply a background subtraction to all frames of a video to detect motion changes. \n",
    "\n",
    "To initialize a background image try:\n",
    "* Using only the first frame \n",
    "* Finding the mean or median over the first $n$ frames.\n",
    "\n",
    "Test it on \"ex/1.avi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "# Find the background image\n",
    "def get_background_image_1frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "    if ret and not frame is None:\n",
    "        return frame\n",
    "    else:\n",
    "        raise ValueError(\"Video is not valid\")\n",
    "    \n",
    "def get_background_image_nframe(video_path, n_frames, aggregation_method):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    idx = 0\n",
    "    while(cap.isOpened() and idx<n_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if ret and not frame is None:\n",
    "            frames.append(frame)\n",
    "            idx += 1\n",
    "        else:\n",
    "            raise ValueError(\"Video is not valid\")\n",
    "\n",
    "    frames = np.stack(frames, axis=-1)\n",
    "\n",
    "    if aggregation_method == \"mean\":\n",
    "        return np.mean(frames, axis=-1)\n",
    "    elif aggregation_method == \"median\":\n",
    "        return np.median(frames, axis=-1)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only mean and median are implemented aggregation methods\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "# Write your solution here\n",
    "# Apply the background subtraction\n",
    "def play_mask_and_image_bckg_sub(video_path, bckg, distance, threshold):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret and not frame is None:\n",
    "                mask = two_frame_difference_mask(frame, bckg, distance, threshold)\n",
    "                display_mask_and_change_image(mask, frame)\n",
    "                clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If we press stop (jupyter GUI) release the video\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "\n",
    "\n",
    "bckg = get_background_image_1frame('LabSession5Images/video.avi')\n",
    "\n",
    "play_mask_and_image_bckg_sub('LabSession5Images/video.avi', bckg, distance=1, threshold=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bckg = get_background_image_nframe('LabSession5Images/video.avi', 100, \"median\")\n",
    "\n",
    "play_mask_and_image_bckg_sub('LabSession5Images/video.avi', bckg, distance=1, threshold=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Sobel Filter Frame-Wise\n",
    "\n",
    "Apply the Sobel kernels to calculate the smooth derivates $\\frac{dI(x, y)}{dx}$, $\\frac{dI(x, y)}{dy}$ along x and y respectively. Visualize the absolute value of the two results.\n",
    "Then, calculate the module of the gradient as $max(abs(\\frac{dI(x, y)}{dx}), abs(\\frac{dI(x, y)}{dy}))$. Do it for each frame of the video and visualize the results. Test it on \"ex/1.avi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your solution here\n",
    "\n",
    "def get_edges_sobels(img):\n",
    "    sobel_ker = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])/4\n",
    "\n",
    "    dIdx = cv2.filter2D(np.float32(img), -1, sobel_ker, (-1,-1))\n",
    "    dIdy = cv2.filter2D(np.float32(img), -1, sobel_ker.T, (-1,-1))\n",
    "\n",
    "    dIdx = np.sum(dIdx, axis=-1)\n",
    "    dIdy = np.sum(dIdy, axis=-1)\n",
    "\n",
    "    dIdx_module = np.abs(dIdx)\n",
    "    dIdy_module = np.abs(dIdy)\n",
    "\n",
    "    return np.maximum(dIdx_module, dIdy_module)\n",
    "\n",
    "\n",
    "def play_video_edges(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret and not frame is None:\n",
    "                frame = get_edges_sobels(frame)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(frame, cmap=\"gray\", vmin=0, vmax=256)\n",
    "                plt.show()\n",
    "                clear_output(wait=True)\n",
    "            else:\n",
    "                cap.release()\n",
    "                print(\"Released Video Resource because ret=False\")\n",
    "                # Break exit the while loops\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If we press stop (jupyter GUI) release the video\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "\n",
    "play_video_edges('LabSession5Images/video.avi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-3.7.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "29f32bed21a42699808201b43d0eead14edbd22a7ed3f1cb678382ea0ed635d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
